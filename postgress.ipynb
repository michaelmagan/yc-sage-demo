{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  web-scraper-order                            web-scraper-start-url  \\\n",
      "0   1725002158-8882  https://www.ycombinator.com/companies?batch=S24   \n",
      "1   1725000592-7697  https://www.ycombinator.com/companies?batch=W23   \n",
      "2   1724993555-2619  https://www.ycombinator.com/companies?batch=S17   \n",
      "3    1724990276-368  https://www.ycombinator.com/companies?batch=S10   \n",
      "4   1725002011-8762  https://www.ycombinator.com/companies?batch=S24   \n",
      "\n",
      "                                           one-liner batch  \\\n",
      "0                    AI-powered patent due diligence   S24   \n",
      "1             We help organizations go passwordless.   W23   \n",
      "2  10by10 is a unique marketplace in the recruiti...   S17   \n",
      "3                                    Memorial sites.   S10   \n",
      "4  We make microbes enabling ultra cheap metal ex...   S24   \n",
      "\n",
      "                 location         type             categories  \\\n",
      "0  San Francisco, CA, USA          B2B                  Legal   \n",
      "1                     NaN          B2B               Security   \n",
      "2  San Francisco, CA, USA          B2B  Recruiting and Talent   \n",
      "3  San Francisco, CA, USA     Consumer      Home and Personal   \n",
      "4  San Francisco, CA, USA  Industrials                    NaN   \n",
      "\n",
      "                                        profile-href  \\\n",
      "0         https://www.ycombinator.com/companies/ai-2   \n",
      "1        https://www.ycombinator.com/companies/0pass   \n",
      "2     https://www.ycombinator.com/companies/10-by-10   \n",
      "3  https://www.ycombinator.com/companies/1000memo...   \n",
      "4     https://www.ycombinator.com/companies/1849-bio   \n",
      "\n",
      "                    url-href    status  ...  founder-5-twitter-href founder-6  \\\n",
      "0  https://www.tryandai.com/    Active  ...                     NaN       NaN   \n",
      "1         https://0pass.com/    Active  ...                     NaN       NaN   \n",
      "2         https://10by10.io/    Active  ...                     NaN       NaN   \n",
      "3       http://ancestry.com/  Acquired  ...                     NaN       NaN   \n",
      "4      https://www.1849.bio/    Active  ...                     NaN       NaN   \n",
      "\n",
      "  founder-6-linkedin-href founder-6-twitter-href founder-7  \\\n",
      "0                     NaN                    NaN       NaN   \n",
      "1                     NaN                    NaN       NaN   \n",
      "2                     NaN                    NaN       NaN   \n",
      "3                     NaN                    NaN       NaN   \n",
      "4                     NaN                    NaN       NaN   \n",
      "\n",
      "  founder-7-linkedin-href  founder-7-twitter-href  founder-8  \\\n",
      "0                     NaN                     NaN        NaN   \n",
      "1                     NaN                     NaN        NaN   \n",
      "2                     NaN                     NaN        NaN   \n",
      "3                     NaN                     NaN        NaN   \n",
      "4                     NaN                     NaN        NaN   \n",
      "\n",
      "   founder-8-linkedin-href founder-8-twitter-href  \n",
      "0                      NaN                    NaN  \n",
      "1                      NaN                    NaN  \n",
      "2                      NaN                    NaN  \n",
      "3                      NaN                    NaN  \n",
      "4                      NaN                    NaN  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "Index(['web-scraper-order', 'web-scraper-start-url', 'one-liner', 'batch',\n",
      "       'location', 'type', 'categories', 'profile-href', 'url-href', 'status',\n",
      "       'founded', 'description', 'launches', 'company-linkedin-href',\n",
      "       'company-twitter-href', 'company-crunchbase-href', 'company-github',\n",
      "       'number-jobs', 'team-size', 'latest_news', 'latest_news-href',\n",
      "       'youtube_link', 'email', 'calendar_link', 'name', 'founder_count',\n",
      "       'founder-1', 'founder-1-linkedin-href', 'founder-1-twitter-href',\n",
      "       'founder-2', 'founder-2-linkedin-href', 'founder-2-twitter-href',\n",
      "       'founder-3', 'founder-3-linkedin-href', 'founder-3-twitter-href',\n",
      "       'founder-4', 'founder-4-linkedin-href', 'founder-4-twitter-href',\n",
      "       'founder-5', 'founder-5-linkedin-href', 'founder-5-twitter-href',\n",
      "       'founder-6', 'founder-6-linkedin-href', 'founder-6-twitter-href',\n",
      "       'founder-7', 'founder-7-linkedin-href', 'founder-7-twitter-href',\n",
      "       'founder-8', 'founder-8-linkedin-href', 'founder-8-twitter-href'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('yc_startups_aggregated_by_company.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env.local')\n",
    "\n",
    "# Retrieve the database URL from the environment variables\n",
    "DATABASE_URL = os.getenv('POSTGRESS_DB')\n",
    "\n",
    "# Update the database URL to use the correct format\n",
    "DATABASE_URL = f\"postgresql://{DATABASE_URL}\"\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(DATABASE_URL)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create the table in the database\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS yc_startups (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    web_scraper_order VARCHAR,\n",
    "    web_scraper_start_url VARCHAR,\n",
    "    one_liner VARCHAR,\n",
    "    batch VARCHAR,\n",
    "    location VARCHAR,\n",
    "    type VARCHAR,\n",
    "    categories VARCHAR,\n",
    "    profile_href VARCHAR,\n",
    "    url_href VARCHAR,\n",
    "    status VARCHAR,\n",
    "    founded FLOAT,\n",
    "    description TEXT,\n",
    "    launches TEXT,\n",
    "    company_linkedin_href VARCHAR,\n",
    "    company_twitter_href VARCHAR,\n",
    "    company_crunchbase_href VARCHAR,\n",
    "    company_github VARCHAR,\n",
    "    number_jobs INTEGER,\n",
    "    team_size FLOAT,\n",
    "    latest_news TEXT,\n",
    "    latest_news_href VARCHAR,\n",
    "    youtube_link VARCHAR,\n",
    "    email VARCHAR,\n",
    "    calendar_link VARCHAR,\n",
    "    name VARCHAR,\n",
    "    founder_count INTEGER,\n",
    "    founders JSONB\n",
    ");\n",
    "\"\"\"\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('yc_startups_aggregated_by_company.csv')\n",
    "\n",
    "# Iterate over the DataFrame and add each row to the database\n",
    "for index, row in df.iterrows():\n",
    "    founders = []\n",
    "    for i in range(1, 9):\n",
    "        if pd.notna(row[f'founder-{i}']):\n",
    "            founders.append({\n",
    "                'name': row[f'founder-{i}'],\n",
    "                'linkedin': row[f'founder-{i}-linkedin-href'] if pd.notna(row[f'founder-{i}-linkedin-href']) else None,\n",
    "                'twitter': row[f'founder-{i}-twitter-href'] if pd.notna(row[f'founder-{i}-twitter-href']) else None\n",
    "            })\n",
    "    \n",
    "    try:\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO yc_startups (\n",
    "            web_scraper_order, web_scraper_start_url, one_liner, batch, location, type, categories, profile_href, url_href, status, founded, description, launches, company_linkedin_href, company_twitter_href, company_crunchbase_href, company_github, number_jobs, team_size, latest_news, latest_news_href, youtube_link, email, calendar_link, name, founder_count, founders\n",
    "        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        cur.execute(insert_query, (\n",
    "            row['web-scraper-order'],\n",
    "            row['web-scraper-start-url'],\n",
    "            row['one-liner'],\n",
    "            row['batch'],\n",
    "            row['location'],\n",
    "            row['type'],\n",
    "            row['categories'],\n",
    "            row['profile-href'],\n",
    "            row['url-href'],\n",
    "            row['status'],\n",
    "            float(row['founded']) if pd.notna(row['founded']) else None,\n",
    "            row['description'],\n",
    "            row['launches'],\n",
    "            row['company-linkedin-href'],\n",
    "            row['company-twitter-href'],\n",
    "            row['company-crunchbase-href'],\n",
    "            row['company-github'],\n",
    "            int(row['number-jobs']) if pd.notna(row['number-jobs']) else None,\n",
    "            float(row['team-size']) if pd.notna(row['team-size']) else None,\n",
    "            row['latest_news'],\n",
    "            row['latest_news-href'],\n",
    "            row['youtube_link'],\n",
    "            row['email'],\n",
    "            row['calendar_link'],\n",
    "            row['name'],\n",
    "            int(row['founder_count']) if pd.notna(row['founder_count']) else None,\n",
    "            json.dumps(founders)\n",
    "        ))\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing row {index}: {e}\")\n",
    "        conn.rollback()  # Rollback the transaction to avoid partial commits\n",
    "\n",
    "# Commit the transaction to save the data to the database\n",
    "try:\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error occurred: {e}\")\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
